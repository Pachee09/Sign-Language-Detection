{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa20c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1505 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.8594 - accuracy: 0.9402WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 10s 62ms/step - loss: 0.8594 - accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "150/151 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0023 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "150/151 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 8.6681e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 8.6681e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "150/151 [============================>.] - ETA: 0s - loss: 6.5345e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 36ms/step - loss: 6.5339e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 5.2486e-04 - accuracy: 1.0000 ETA: 0s - loss: 5.2626e-04 - accuracy: 1.00WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 36ms/step - loss: 5.2486e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 4.3436e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 38ms/step - loss: 4.3436e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "150/151 [============================>.] - ETA: 0s - loss: 3.7403e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 3.7388e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "150/151 [============================>.] - ETA: 0s - loss: 3.2433e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 3.2451e-04 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - ETA: 0s - loss: 2.8776e-04 - accuracy: 1.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "151/151 [==============================] - 6s 39ms/step - loss: 2.8776e-04 - accuracy: 1.0000 - lr: 0.0010\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6868/1574466964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For getting next batch of imgs...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "train_path = r'C:\\Users\\Lenovo\\Desktop\\FinalProject\\train'\n",
    "test_path = r'C:\\Users\\Lenovo\\Desktop\\FinalProject\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)\n",
    "\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n",
    "imgs, labels = next(train_batches) # For getting next batch of imgs...\n",
    "\n",
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#model.save('best_model_dataflair.h5')\n",
    "model.save('best_model_dataflair3.h5')\n",
    "\n",
    "print(history2.history)\n",
    "\n",
    "imgs, labels = next(test_batches)\n",
    "\n",
    "model = keras.models.load_model(r\"best_model_dataflair3.h5\")\n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "scores #[loss, accuracy] on test data...\n",
    "model.metrics_names\n",
    "\n",
    "\n",
    "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "history2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad6356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
